\chapter{Introduction}

\section{Background}
In order to assist in general tasks, autonomous robots should be able to interact with dynamic objects in unstructured environments. Robot manipulation of objects is the key component in all autonomous robot applications requiring interaction with environment. In vision based robot manipulation, robot has to measure the environment state using camera and take actions according the measured state and goal. The main challenges in here are interpreting the noisy high dimensional data from camera and deciding actions according to stochastic and non stationary environment state.

Methods for robot manipulation can be broadly classified into traditional and data driven methods. In traditional methods, data from camera is interpreted using computer vision algorithms and actions are hand coded based on interpreted state. This approach works well for robots deployed for specific task like in automated production lines. But in stochastic and non stationary environments, it is not possible to hand code actions for all environment states. On the other hand data driven methods, particularly reinforcement learning have shown great potential in this use case. In reinforcement learning, an agent learns to take actions (policy) based on measured environment state by interacting with the environment through trial and error for maximising a feedback signal (reward or value function). The main challenge in this method is requirement of large amount of data for agent to learn. Collecting large amount of data from real robot will be slow and expensive and might require manual intervention. Instead, for faster and cheaper development, agent can be trained on simulated robot manipulation environment. However policies trained on simulated environments are not directly transferable to real robots due to various differences between simulation and real environments.

\section{Research Gap}
Current testbeds available for vision based robot manipulation for reinforcement learning have following limitations
\begin{itemize}
	\item Slow training data collection speed
	\item Non standard/readily available frameworks used
\end{itemize}

\section{Objectives}
\begin{itemize}
	\item Improve RL model training speed by running multiple simulations in parallel
	\item Use standard frameworks that support training distributed RL algorithms
	\item Flexibility for adding different types of robot manipulation tasks like grasping, moving etc.
\end{itemize}

\section{Outline of Report}
\begin{itemize}
	\item Chapter 1 gives an introduction to project and outline of this report
	\item Chapter 2 gives an overview of previous works done
	\item Chapter 3 gives details of simulation and hardware setup used to train reinforcement learning agents
	\item Chapter 4 gives the specifications of simulation environment and hardware used for evaluating testbed
	\item Chapter 5 gives the performance of simulator and testbed evaluation results of PPO in table clearing environment
\end{itemize}