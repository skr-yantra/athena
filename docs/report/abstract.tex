\newpage
\addcontentsline{toc}{chapter}{ABSTRACT}
\chapter*{\MakeUppercase{Abstract}}
In order to assist in general tasks, autonomous robots should be able to interact with dynamic objects in unstructured environments. Robot manipulation of objects is the key component in all autonomous robot applications requiring interaction with environment. In vision based robot manipulation, robot has to measure the environment state using camera and take actions according the measured state and goal. The main challenges in here are interpreting the noisy high dimensional data from camera and deciding actions according to stochastic and non stationary environment state.

Work done by Michel Breyer et. al. \cite{tasksimplification} found that using autoencoder to reduce dimensionality of camera data and using curriculum learning reduced the training time of agents. Also by using shaped reward functions instead of sparse reward function, they obtained 98\% success rate on simulated environment. They also found that using RANSAC for detecting and filtering surfaces from camera data while using policies trained from simulated environment on real robot gave 78\% success rate. 

This project will evaluate the performance of hierarchical reinforcement learning methods for vision based robot manipulation. Traditional reinforcement learning methods are data inefficient (require lot of data for training), difficult to scale (due to large action and/or state space) and brittle due to over specialisation (difficult to transfer their experience to new even similar environments) \cite{gradient}. Hierarchical reinforcement learning are intended to address these issues by learning to operate on different levels of temporal abstraction. Using this method, the entire task of robot manipulation can be split into smaller sub-tasks like reaching, grasping, lifting etc. 