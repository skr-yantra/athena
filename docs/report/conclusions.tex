\chapter{Conclusions and Future Work}

\section{Conclusions}
A testbed that aids in the development and benchmarking of various RL algorithms for robot manipulation tasks is developed. By using RayLib, the testbed can scale training speed with computational power. Also the testbed is integrated with CometML platform for experiment logging and tracking. The testbed is evaluated using PPO RL algorithm and the simulator performance is benchmarked at various configurations. Evaluation using PPO RL algorithm showed its low sample efficiency and high reliance on reward shaping.

\section{Future works}
The current testbed is evaluated only using PPO algorithm. It would be beneficial to evaluate using other common RL algorithms like DDPG and RHPO. Also the testbed currently only provides table clearning robot manipulation task. Adding common tasks like stacking will be beneficial. Also evaluating the performance of policies trained using simulated environment on real robot will be beneficial