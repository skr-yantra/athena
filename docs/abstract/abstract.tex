% Created by Yantra on 2019-08-15.
% Copyright (c) 2019 .
\documentclass[11pt,a4paper]{article}

\usepackage{titling}
\usepackage[a4paper,left=2cm,right=2cm,top=3cm,bottom=3cm]{geometry}
\usepackage{tabularx}

\setlength{\droptitle}{-7em} 

\title{Vision Based Robot Manipulation Testbed for Reinforcement Learning \vspace{-6ex}}
\date{}

\begin{document}

\maketitle

In order to assist in general tasks, autonomous robots should be able to interact with dynamic objects in unstructured environments. Robot manipulation of objects is the key component in all autonomous robot applications requiring interaction with environment. In vision based robot manipulation, robot has to measure the environment state using camera and take actions according the measured state and goal. The main challenges in here are interpreting the noisy high dimensional data from camera and deciding actions according to stochastic and non stationary environment state.

This project will develop a testbed for evaluating and developing various reinforcement learning algorithms for vision based robot manipulation tasks. Reinforcement learning algorithms usually have very low data efficiency and require lot of training data. Traditional testbeds available for robot manipulation tasks are not designed for parallel/distributed training making them slow for collecting training data. Developing a testbed which can run multiple simulations in parallel and is flexible enough for testing different reinforcement learning algorithms on different tasks like grasping, moving etc. will aid in developing RL algorithms faster and can be used as a standard framework for benchmarking different RL algorithms.

\vspace{10mm}

\begin{tabularx}{\textwidth}{c X c}
\textbf{Guided by} & & \textbf{Submitted by} \\
Linu Shine & & Sreejith Krishnan R \\
Electronics and Communication Engineering & & TVE18ECRA17 \\
College of Engineering, Trivandrum & & Robotics and Automation \\
\end{tabularx}

\begin{thebibliography}{9}
\bibitem{visual-robot-manipulation} 
Fan, Linxi and Zhu, Yuke and Zhu, Jiren and Liu, Zihua and Zeng, Orien and Gupta, Anchit and Creus-Costa, Joan and Savarese, Silvio and Fei-Fei, Li, 
\textit{SURREAL: Open-Source Reinforcement Learning Framework and Robot Manipulation Benchmark}. 
Conference on Robot Learning, 2018

\bibitem{visual-robot-manipulation} 
M. Breyer, F. Furrer, T. Novkovic, R. Siegwart and J. Nieto, 
\textit{Comparing Task Simplifications to Learn Closed-Loop Object Picking Using Deep Reinforcement Learning}. 
IEEE Robotics and Automation Letters, vol. 4, no. 2, pp. 1549-1556, April 2019

\bibitem{thegradient} 
The Gradient - \textit{The Promise of Hierarchical Reinforcement Learning}
\\\texttt{https://thegradient.pub/the-promise-of-hierarchical-reinforcement-learning/}

\bibitem{google} 
D. Quillen, E. Jang, O. Nachum, C. Finn, J. Ibarz and S. Levine, 
\textit{Deep Reinforcement Learning for Vision-Based Robotic Grasping: A Simulated Comparative Evaluation of Off-Policy Methods}.
IEEE International Conference on Robotics and Automation (ICRA), Brisbane, QLD, 2018, pp. 6284-6291

\bibitem{google1} 
Eric Jang, Coline Devin, Vincent Vanhoucke, Sergey Levine, 
\textit{Grasp2Vec: Learning Object Representations from Self-Supervised Grasping}.
Proceedings of The 2nd Conference on Robot Learning, in PMLR 87:99-112 (2018)
\end{thebibliography}
\end{document}